[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
authors = [{name = "Unknown"}]
description = "Web page image scraper with optional Google Drive upload"
license = {text = "MIT"}
name = "image-saver"
readme = "README.md"
requires-python = ">=3.11"
version = "0.1.0"

dependencies = [
  "requests>=2.32.0",
  "beautifulsoup4>=4.12.0",
  "fastapi>=0.115.0",
  "uvicorn[standard]>=0.30.0",
  "httpx>=0.27.0",
  "streamlit>=1.38.0",
  "ddgs>=8.0.0",
]

[project.optional-dependencies]
# Service Account authentication for Google Drive
drive = ["google-api-python-client>=2.149.0", "google-auth>=2.35.0"]

dev = [
  "pre-commit>=3.7.0",
  "ruff>=0.6.9",
]

# Note: rclone support requires the rclone CLI tool to be installed separately:
#   macOS: brew install rclone
#   Linux: curl https://rclone.org/install.sh | sudo bash
#   Or use: ./scripts/setup_rclone.sh

[project.scripts]
# CLIエントリポイント: uv run image-scrape で実行可能
image-scrape = "src.cli.scrape_images:main"

[tool.ruff]
line-length = 120
target-version = "py311"
src = ["src", "tests"]

[tool.ruff.lint]
select = ["B", "E", "F", "I"]

[tool.ruff.lint.isort]
known-first-party = ["src"]

[tool.hatch.build.targets.wheel]
packages = ["src"]

[tool.uv]
package = true  # project.scripts のエントリポイントを有効化

